{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import  OrdinalEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 171209, number of negative: 171012\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3929\n",
      "[LightGBM] [Info] Number of data points in the train set: 342221, number of used features: 62\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500288 -> initscore=0.001151\n",
      "[LightGBM] [Info] Start training from score 0.001151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [20:36:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "\n",
      "모델별 ROC-AUC 점수 및 학습 시간:\n",
      "LightGBM: ROC-AUC = 0.8955, 학습 시간 = 13.03초\n",
      "XGBoost: ROC-AUC = 0.9070, 학습 시간 = 0.93초\n",
      "Ensemble: ROC-AUC = 0.9074, 학습 시간 = 0.00초\n",
      "Split TEST ROC-AUC 점수 \n",
      "\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 190123, number of negative: 190123\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3920\n",
      "[LightGBM] [Info] Number of data points in the train set: 380246, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [20:36:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  probability\n",
      "0  TEST_00000     0.000806\n",
      "1  TEST_00001     0.002128\n",
      "2  TEST_00002     0.136237\n",
      "3  TEST_00003     0.151065\n",
      "4  TEST_00004     0.515323\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = [\n",
    "    \"임신 시도 또는 마지막 임신 경과 연수\",\n",
    "    \"총 생성 배아 수\",\n",
    "    \"미세주입된 난자 수\",\n",
    "    \"미세주입에서 생성된 배아 수\",\n",
    "    \"이식된 배아 수\",\n",
    "    \"미세주입 배아 이식 수\",\n",
    "    \"저장된 배아 수\",\n",
    "    \"미세주입 후 저장된 배아 수\",\n",
    "    \"해동된 배아 수\",\n",
    "    \"해동 난자 수\",\n",
    "    \"수집된 신선 난자 수\",\n",
    "    \"저장된 신선 난자 수\",\n",
    "    \"혼합된 난자 수\",\n",
    "    \"파트너 정자와 혼합된 난자 수\",\n",
    "    \"기증자 정자와 혼합된 난자 수\",\n",
    "    \"난자 채취 경과일\",\n",
    "    \"난자 해동 경과일\",\n",
    "    \"난자 혼합 경과일\",\n",
    "    \"배아 이식 경과일\",\n",
    "    \"배아 해동 경과일\"\n",
    "]\n",
    "\n",
    "categorical_columns = [\n",
    "    \"시술 시기 코드\",\n",
    "    \"시술 당시 나이\",\n",
    "    \"시술 유형\",\n",
    "    \"특정 시술 유형\",\n",
    "    \"배란 자극 여부\",\n",
    "    \"배란 유도 유형\",\n",
    "    \"단일 배아 이식 여부\",\n",
    "    \"착상 전 유전 검사 사용 여부\",\n",
    "    \"착상 전 유전 진단 사용 여부\",\n",
    "    \"남성 주 불임 원인\",\n",
    "    \"남성 부 불임 원인\",\n",
    "    \"여성 주 불임 원인\",\n",
    "    \"여성 부 불임 원인\",\n",
    "    \"부부 주 불임 원인\",\n",
    "    \"부부 부 불임 원인\",\n",
    "    \"불명확 불임 원인\",\n",
    "    \"불임 원인 - 난관 질환\",\n",
    "    \"불임 원인 - 남성 요인\",\n",
    "    \"불임 원인 - 배란 장애\",\n",
    "    \"불임 원인 - 여성 요인\",\n",
    "    \"불임 원인 - 자궁경부 문제\",\n",
    "    \"불임 원인 - 자궁내막증\",\n",
    "    \"불임 원인 - 정자 농도\",\n",
    "    \"불임 원인 - 정자 면역학적 요인\",\n",
    "    \"불임 원인 - 정자 운동성\",\n",
    "    \"불임 원인 - 정자 형태\",\n",
    "    \"배아 생성 주요 이유\",\n",
    "    \"총 시술 횟수\",\n",
    "    \"클리닉 내 총 시술 횟수\",\n",
    "    \"IVF 시술 횟수\",\n",
    "    \"DI 시술 횟수\",\n",
    "    \"총 임신 횟수\",\n",
    "    \"IVF 임신 횟수\",\n",
    "    \"DI 임신 횟수\",\n",
    "    \"총 출산 횟수\",\n",
    "    \"IVF 출산 횟수\",\n",
    "    \"DI 출산 횟수\",\n",
    "    \"난자 출처\",\n",
    "    \"정자 출처\",\n",
    "    \"난자 기증자 나이\",\n",
    "    \"정자 기증자 나이\",\n",
    "    \"동결 배아 사용 여부\",\n",
    "    \"신선 배아 사용 여부\",\n",
    "    \"기증 배아 사용 여부\",\n",
    "    \"대리모 여부\",\n",
    "    \"PGD 시술 여부\",\n",
    "    \"PGS 시술 여부\"\n",
    "]\n",
    "\n",
    "train = pd.read_csv('./data/train.csv').drop(columns=['ID'])\n",
    "test = pd.read_csv('./data/test.csv').drop(columns=['ID'])\n",
    "\n",
    "X = train.drop('임신 성공 여부', axis=1)\n",
    "y = train['임신 성공 여부']\n",
    "\n",
    "# 카테고리형 컬럼들을 문자열로 변환\n",
    "for col in categorical_columns:\n",
    "    X[col] = X[col].astype(str)\n",
    "    test[col] = test[col].astype(str)\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "X_train_encoded = X.copy()\n",
    "X_train_encoded[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])\n",
    "\n",
    "X_test_encoded = test.copy()\n",
    "X_test_encoded[categorical_columns] = ordinal_encoder.transform(test[categorical_columns])\n",
    "\n",
    "# 수치형 컬럼들을 0으로 채움\n",
    "X_train_encoded[numeric_columns] = X_train_encoded[numeric_columns].fillna(0)\n",
    "X_test_encoded[numeric_columns] = X_test_encoded[numeric_columns].fillna(0)\n",
    "\n",
    "# 스케일링 적용\n",
    "scaler = StandardScaler()\n",
    "X_train_encoded[numeric_columns] = scaler.fit_transform(X_train_encoded[numeric_columns])\n",
    "X_test_encoded[numeric_columns] = scaler.transform(X_test_encoded[numeric_columns])\n",
    "\n",
    "# 데이터 불균형 확인 및 SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_encoded, y = smote.fit_resample(X_train_encoded, y)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_encoded, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# 결과 저장 딕셔너리\n",
    "auc_scores = {}\n",
    "training_times = {}\n",
    "\n",
    "# # 0. Extra Trees Classifier\n",
    "# start_time = time.time()\n",
    "# ETC_model = ExtraTreesClassifier(random_state=42)\n",
    "# ETC_model.fit(X_train, y_train)\n",
    "# training_times['Extra Trees'] = time.time() - start_time\n",
    "# ETC_pred_proba = ETC_model.predict_proba(X_test)[:, 1]\n",
    "# auc_scores['Extra Trees'] = roc_auc_score(y_test, ETC_pred_proba)\n",
    "\n",
    "# # 1. Random Forest\n",
    "# start_time = time.time()\n",
    "\n",
    "# # RandomizedSearchCV를 통한 랜덤 포레스트 튜닝\n",
    "# rf_params = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [10, 20, 30, None],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "\n",
    "# rf_random_search = RandomizedSearchCV(\n",
    "#     estimator=RandomForestClassifier(random_state=42),\n",
    "#     param_distributions=rf_params,\n",
    "#     n_iter=10,\n",
    "#     cv=3,\n",
    "#     scoring='roc_auc',\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # Random Forest 튜닝 및 학습\n",
    "# rf_random_search.fit(X_train, y_train)\n",
    "# rf_model = rf_random_search.best_estimator_\n",
    "\n",
    "# rf_pred_proba = rf_model.predict_proba(X_test_encoded)[:, 1]\n",
    "# auc_rf = roc_auc_score(y_test, rf_pred_proba)\n",
    "# auc_scores['Random Forest'] = roc_auc_score(y_test, rf_pred_proba)\n",
    "\n",
    "# 2. LightGBM\n",
    "start_time = time.time()\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_columns)\n",
    "lgb_test = lgb.Dataset(X_test, label=y_test, reference=lgb_train)\n",
    "\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 50,\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.1\n",
    "}\n",
    "\n",
    "lgb_model = lgb.train(lgb_params, lgb_train, num_boost_round=1000, valid_sets=[lgb_test])\n",
    "training_times['LightGBM'] = time.time() - start_time\n",
    "lgb_pred_proba = lgb_model.predict(X_test)\n",
    "auc_scores['LightGBM'] = roc_auc_score(y_test, lgb_pred_proba)\n",
    "\n",
    "\n",
    "# 3. XGBoost\n",
    "start_time = time.time()\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='auc', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "training_times['XGBoost'] = time.time() - start_time\n",
    "xgb_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "auc_scores['XGBoost'] = roc_auc_score(y_test, xgb_pred_proba)\n",
    "\n",
    "# 4. 앙상블\n",
    "ensemble_pred_proba = (lgb_pred_proba + xgb_pred_proba) / 2\n",
    "auc_scores['Ensemble'] = roc_auc_score(y_test, ensemble_pred_proba)\n",
    "training_times['Ensemble'] = 0\n",
    "\n",
    "# 결과 출력\n",
    "print(\"________________________________________________________________________________\")\n",
    "print(\"\\n모델별 ROC-AUC 점수 및 학습 시간:\")\n",
    "for model in auc_scores:\n",
    "    print(f\"{model}: ROC-AUC = {auc_scores[model]:.4f}, 학습 시간 = {training_times[model]:.2f}초\")\n",
    "print(\"________________________________________________________________________________ \\n\")\n",
    "\n",
    "# ________________REAL TRAIN_____________\n",
    "\n",
    "# etc_pred_proba = ETC_model.predict_proba(X_test_encoded)[:, 1]\n",
    "# rf_pred_proba = rf_model.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train_encoded, label=y, categorical_feature=categorical_columns)\n",
    "lgb_model = lgb.train(lgb_params, lgb_train, num_boost_round=1000)\n",
    "lgb_pred_proba = lgb_model.predict(X_test_encoded)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='auc', random_state=42)\n",
    "xgb_model.fit(X_train_encoded, y)\n",
    "xgb_pred_proba = xgb_model.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "\n",
    "# 결과 제출 file\n",
    "sample_submission = pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "# 앙상블 (LightGBM과 XGBoost 예측값 평균)\n",
    "ensemble_pred_proba = (lgb_pred_proba + xgb_pred_proba) / 2\n",
    "sample_submission['probability'] = ensemble_pred_proba\n",
    "sample_submission.to_csv('./submit/ensemble_submit.csv', index=False)\n",
    "\n",
    "# sample_submission['probability'] = etc_pred_proba\n",
    "# sample_submission.to_csv('./etc_submit.csv', index=False)\n",
    "# sample_submission['probability'] = rf_pred_proba   \n",
    "# sample_submission.to_csv('./rf_submit.csv', index=False)\n",
    "sample_submission['probability'] = lgb_pred_proba\n",
    "sample_submission.to_csv('./submit/lgb_submit.csv', index=False)\n",
    "\n",
    "sample_submission['probability'] = xgb_pred_proba\n",
    "sample_submission.to_csv('./submit/xgb_submit.csv', index=False)\n",
    "\n",
    "print(sample_submission.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피쳐 제거 이후 학습..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 중요도 추출\n",
    "feature_importances = xgb_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importances = pd.Series(xgb_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# 중요도 기준으로 상위 10개만 선택\n",
    "top_features = feature_importances[feature_importances < 0.002].index  # 중요도가 0.01 이상인 컬럼만 선택\n",
    "X_selected = X[top_features]\n",
    "\n",
    "# 선택된 컬럼으로 학습 진행\n",
    "print(f\"선택된 컬럼: {list(top_features)}\")\n",
    "print(f\"선택된 컬럼 개수: {len(list(top_features))}\")\n",
    "\n",
    "# 선택된 컬럼\n",
    "selected_columns = ['여성 주 불임 원인', '해동된 배아 수', '총 시술 횟수', '부부 주 불임 원인', \n",
    "                   '미세주입에서 생성된 배아 수', '해동 난자 수', '기증자 정자와 혼합된 난자 수', \n",
    "                   '미세주입 후 저장된 배아 수', '불명확 불임 원인', '대리모 여부', \n",
    "                   '남성 주 불임 원인', '난자 혼합 경과일', '저장된 신선 난자 수', \n",
    "                   '불임 원인 - 정자 운동성', '불임 원인 - 정자 형태', '불임 원인 - 자궁경부 문제', \n",
    "                   '난자 해동 경과일', '난자 채취 경과일', '불임 원인 - 여성 요인', \n",
    "                   '불임 원인 - 정자 면역학적 요인']\n",
    "selected_columns = ['저장된 신선 난자 수', '불임 원인 - 정자 운동성', '난자 채취 경과일', '난자 해동 경과일',\n",
    "                     '불임 원인 - 자궁경부 문제', '불임 원인 - 여성 요인', '불임 원인 - 정자 면역학적 요인',\n",
    "                       '동결 배아 사용 여부']\n",
    "\n",
    "\n",
    "# 선택된 컬럼 제거\n",
    "X_train_new = X_train.drop(columns=selected_columns, errors='ignore')\n",
    "X_test_new = X_test.drop(columns=selected_columns, errors='ignore')  # 테스트 데이터도 동일하게 처리\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "auc_scores_new = {}\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='auc', random_state=42)\n",
    "xgb_model.fit(X_train_new, y_train)\n",
    "xgb_pred_proba = xgb_model.predict_proba(X_test_new)[:, 1]\n",
    "auc_scores_new['XGBoost'] = roc_auc_score(y_test, xgb_pred_proba)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"제외된 컬럼 이후 모델별 ROC-AUC 점수:\")\n",
    "for model, auc in auc_scores_new.items():\n",
    "    print(f\"{model}: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
