{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import  OrdinalEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "numeric_columns = [\n",
    "    \"임신 시도 또는 마지막 임신 경과 연수\",\n",
    "    \"총 생성 배아 수\",\n",
    "    \"미세주입된 난자 수\",\n",
    "    \"미세주입에서 생성된 배아 수\",\n",
    "    \"이식된 배아 수\",\n",
    "    \"미세주입 배아 이식 수\",\n",
    "    \"저장된 배아 수\",\n",
    "    \"미세주입 후 저장된 배아 수\",\n",
    "    \"해동된 배아 수\",\n",
    "    \"해동 난자 수\",\n",
    "    \"수집된 신선 난자 수\",\n",
    "    \"저장된 신선 난자 수\",\n",
    "    \"혼합된 난자 수\",\n",
    "    \"파트너 정자와 혼합된 난자 수\",\n",
    "    \"기증자 정자와 혼합된 난자 수\",\n",
    "    \"난자 채취 경과일\",\n",
    "    \"난자 해동 경과일\",\n",
    "    \"난자 혼합 경과일\",\n",
    "    \"배아 이식 경과일\",\n",
    "    \"배아 해동 경과일\"\n",
    "]\n",
    "\n",
    "categorical_columns = [\n",
    "    \"시술 시기 코드\",\n",
    "    \"시술 당시 나이\",\n",
    "    \"시술 유형\",\n",
    "    \"특정 시술 유형\",\n",
    "    \"배란 자극 여부\",\n",
    "    \"배란 유도 유형\",\n",
    "    \"단일 배아 이식 여부\",\n",
    "    \"착상 전 유전 검사 사용 여부\",\n",
    "    \"착상 전 유전 진단 사용 여부\",\n",
    "    \"남성 주 불임 원인\",\n",
    "    \"남성 부 불임 원인\",\n",
    "    \"여성 주 불임 원인\",\n",
    "    \"여성 부 불임 원인\",\n",
    "    \"부부 주 불임 원인\",\n",
    "    \"부부 부 불임 원인\",\n",
    "    \"불명확 불임 원인\",\n",
    "    \"불임 원인 - 난관 질환\",\n",
    "    \"불임 원인 - 남성 요인\",\n",
    "    \"불임 원인 - 배란 장애\",\n",
    "    \"불임 원인 - 여성 요인\",\n",
    "    \"불임 원인 - 자궁경부 문제\",\n",
    "    \"불임 원인 - 자궁내막증\",\n",
    "    \"불임 원인 - 정자 농도\",\n",
    "    \"불임 원인 - 정자 면역학적 요인\",\n",
    "    \"불임 원인 - 정자 운동성\",\n",
    "    \"불임 원인 - 정자 형태\",\n",
    "    \"배아 생성 주요 이유\",\n",
    "    \"총 시술 횟수\",\n",
    "    \"클리닉 내 총 시술 횟수\",\n",
    "    \"IVF 시술 횟수\",\n",
    "    \"DI 시술 횟수\",\n",
    "    \"총 임신 횟수\",\n",
    "    \"IVF 임신 횟수\",\n",
    "    \"DI 임신 횟수\",\n",
    "    \"총 출산 횟수\",\n",
    "    \"IVF 출산 횟수\",\n",
    "    \"DI 출산 횟수\",\n",
    "    \"난자 출처\",\n",
    "    \"정자 출처\",\n",
    "    \"난자 기증자 나이\",\n",
    "    \"정자 기증자 나이\",\n",
    "    \"동결 배아 사용 여부\",\n",
    "    \"신선 배아 사용 여부\",\n",
    "    \"기증 배아 사용 여부\",\n",
    "    \"대리모 여부\",\n",
    "    \"PGD 시술 여부\",\n",
    "    \"PGS 시술 여부\"\n",
    "]\n",
    "\n",
    "# === 이상치 대체 (Winsorizing) 함수 정의 ===\n",
    "def winsorize(df, numeric_cols, factor=1.5):\n",
    "    df_new = df.copy()\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df_new[col].quantile(0.25)\n",
    "        Q3 = df_new[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - factor * IQR\n",
    "        upper_bound = Q3 + factor * IQR\n",
    "        df_new[col] = df_new[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "    return df_new\n",
    "\n",
    "train = pd.read_csv('./data/train.csv').drop(columns=['ID'])\n",
    "test = pd.read_csv('./data/test.csv').drop(columns=['ID'])\n",
    "\n",
    "train = winsorize(train, numeric_columns, factor=1.5)\n",
    "test = winsorize(test, numeric_columns, factor=1.5)\n",
    "\n",
    "X = train.drop('임신 성공 여부', axis=1)\n",
    "y = train['임신 성공 여부']\n",
    "\n",
    "# 카테고리형 컬럼들을 문자열로 변환\n",
    "for col in categorical_columns:\n",
    "    X[col] = X[col].astype(str)\n",
    "    test[col] = test[col].astype(str)\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "X_train_encoded = X.copy()\n",
    "X_train_encoded[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])\n",
    "\n",
    "X_test_encoded = test.copy()\n",
    "X_test_encoded[categorical_columns] = ordinal_encoder.transform(test[categorical_columns])\n",
    "\n",
    "# 수치형 컬럼들을 0으로 채움\n",
    "X_train_encoded[numeric_columns] = X_train_encoded[numeric_columns].fillna(0)\n",
    "X_test_encoded[numeric_columns] = X_test_encoded[numeric_columns].fillna(0)\n",
    "\n",
    "# categorical_feature에 인덱스를 전달\n",
    "categorical_feature_indices = [X_train_encoded.columns.get_loc(col) for col in categorical_columns]\n",
    "\n",
    "# 스케일링 적용\n",
    "scaler = StandardScaler()\n",
    "X_train_encoded[numeric_columns] = scaler.fit_transform(X_train_encoded[numeric_columns])\n",
    "X_test_encoded[numeric_columns] = scaler.transform(X_test_encoded[numeric_columns])\n",
    "\n",
    "# # 데이터 불균형 확인 및 SMOTE 적용\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_encoded, y = smote.fit_resample(X_train_encoded, y)\n",
    "\n",
    "# 데이터 불균형 확인 및 SMOTE + Tomek 적용\n",
    "smt = SMOTETomek(sampling_strategy=0.8, random_state=42)\n",
    "X_train_encoded, y = smt.fit_resample(X_train_encoded, y)\n",
    "\n",
    "# Feature Selection (SelectKBest)\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=40)  # 가장 중요한 40개의 변수를 선택\n",
    "X_train_encoded = selector.fit_transform(X_train_encoded, y)\n",
    "X_test_encoded = selector.transform(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 96877, number of negative: 122227\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8005\n",
      "[LightGBM] [Info] Number of positive: 96877, number of negative: 122226\n",
      "[LightGBM] [Info] Number of positive: 96876, number of negative: 122227\n",
      "[LightGBM] [Info] Number of data points in the train set: 219104, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442151 -> initscore=-0.232438\n",
      "[LightGBM] [Info] Start training from score -0.232438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8931\n",
      "[LightGBM] [Info] Number of data points in the train set: 219103, number of used features: 40\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8112\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442153 -> initscore=-0.232430\n",
      "[LightGBM] [Info] Start training from score -0.232430\n",
      "[LightGBM] [Info] Number of data points in the train set: 219103, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442148 -> initscore=-0.232448\n",
      "[LightGBM] [Info] Start training from score -0.232448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 145315, number of negative: 183340\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8851\n",
      "[LightGBM] [Info] Number of data points in the train set: 328655, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442151 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Start training from score -0.232439\n",
      "LightGBM 최적 파라미터: {'learning_rate': 0.01, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 70}\n"
     ]
    }
   ],
   "source": [
    "# -------------------------- 3. 하이퍼파라미터 튜닝 --------------------------\n",
    "# LightGBM 하이퍼파라미터 그리드 (scikit-learn API 사용)\n",
    "lgb_param_grid = {\n",
    "    'n_estimators': [1000],\n",
    "    'learning_rate': [0.01],\n",
    "    'num_leaves': [70],\n",
    "    'max_depth': [-1]\n",
    "}\n",
    "\n",
    "lgb_est = LGBMClassifier(random_state=42, objective='binary')\n",
    "grid_lgb = GridSearchCV(lgb_est, lgb_param_grid, scoring='roc_auc', cv=3, n_jobs=-1, verbose=1)\n",
    "grid_lgb.fit(X_train_encoded, y)\n",
    "best_lgb = grid_lgb.best_estimator_\n",
    "print(\"LightGBM 최적 파라미터:\", grid_lgb.best_params_)\n",
    "# LightGBM 최적 파라미터: {'learning_rate': 0.01, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 70}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "XGBoost 최적 파라미터: {'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 11, 'n_estimators': 300, 'subsample': 0.8}\n",
      "________________________________________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost 하이퍼파라미터 그리드\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [300],\n",
    "    'learning_rate': [0.05],\n",
    "    'max_depth': [11],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.7],\n",
    "    'gamma': [0]\n",
    "}\n",
    "\n",
    "xgb_est = XGBClassifier(eval_metric='auc', random_state=42)\n",
    "grid_xgb = GridSearchCV(xgb_est, xgb_param_grid, scoring='roc_auc', cv=3, n_jobs=-1, verbose=1)\n",
    "grid_xgb.fit(X_train_encoded, y)\n",
    "best_xgb = grid_xgb.best_estimator_\n",
    "print(\"XGBoost 최적 파라미터:\", grid_xgb.best_params_)\n",
    "# XGBoost 최적 파라미터: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 300, 'subsample': 0.8}\n",
    "print(\"________________________________________________________________________________ \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 116252, number of negative: 146672\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8835\n",
      "[LightGBM] [Info] Number of data points in the train set: 262924, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442151 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Start training from score -0.232439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 116252, number of negative: 146672\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8835\n",
      "[LightGBM] [Info] Number of data points in the train set: 262924, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442151 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Start training from score -0.232439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 77502, number of negative: 97781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8056\n",
      "[LightGBM] [Info] Number of data points in the train set: 175283, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442154 -> initscore=-0.232427\n",
      "[LightGBM] [Info] Start training from score -0.232427\n",
      "[LightGBM] [Info] Number of positive: 77501, number of negative: 97782\n",
      "[LightGBM] [Info] Number of positive: 77501, number of negative: 97781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8009\n",
      "[LightGBM] [Info] Number of data points in the train set: 175283, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442148 -> initscore=-0.232450\n",
      "[LightGBM] [Info] Start training from score -0.232450\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8905\n",
      "[LightGBM] [Info] Number of data points in the train set: 175282, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442150 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Start training from score -0.232439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 116252, number of negative: 146672\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8669\n",
      "[LightGBM] [Info] Number of data points in the train set: 262924, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442151 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Start training from score -0.232439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 116252, number of negative: 146672\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8669\n",
      "[LightGBM] [Info] Number of data points in the train set: 262924, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442151 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Start training from score -0.232439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [LightGBM] [Info] Number of positive: 77501, number of negative: 97781\n",
      "Number of positive: 77502, number of negative: 97781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8061\n",
      "[LightGBM] [Info] Number of positive: 77501, number of negative: 97782\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8905\n",
      "[LightGBM] [Info] Number of data points in the train set: 175283, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442154 -> initscore=-0.232427\n",
      "[LightGBM] [Info] Start training from score -0.232427\n",
      "[LightGBM] [Info] Number of data points in the train set: 175282, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442150 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Start training from score -0.232439\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7949\n",
      "[LightGBM] [Info] Number of data points in the train set: 175283, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442148 -> initscore=-0.232450\n",
      "[LightGBM] [Info] Start training from score -0.232450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 116252, number of negative: 146672\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8838\n",
      "[LightGBM] [Info] Number of data points in the train set: 262924, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442151 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Start training from score -0.232439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 116252, number of negative: 146672\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8838\n",
      "[LightGBM] [Info] Number of data points in the train set: 262924, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442151 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Start training from score -0.232439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 77501, number of negative: 97781\n",
      "[LightGBM] [Info] Number of positive: 77502, number of negative: 97781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8904\n",
      "[LightGBM] [Info] Number of data points in the train set: 175282, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442150 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Start training from score -0.232439\n",
      "[LightGBM] [Info] Number of positive: 77501, number of negative: 97782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8065\n",
      "[LightGBM] [Info] Number of data points in the train set: 175283, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442154 -> initscore=-0.232427\n",
      "[LightGBM] [Info] Start training from score -0.232427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8011\n",
      "[LightGBM] [Info] Number of data points in the train set: 175283, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442148 -> initscore=-0.232450\n",
      "[LightGBM] [Info] Start training from score -0.232450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 116252, number of negative: 146672\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8664\n",
      "[LightGBM] [Info] Number of data points in the train set: 262924, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442151 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Start training from score -0.232439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 116252, number of negative: 146672\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8664\n",
      "[LightGBM] [Info] Number of data points in the train set: 262924, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442151 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Start training from score -0.232439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 77501, number of negative: 97781\n",
      "[LightGBM] [Info] Number of positive: 77501, number of negative: 97782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8917\n",
      "[LightGBM] [Info] Number of data points in the train set: 175282, number of used features: 40\n",
      "[LightGBM] [Info] Number of positive: 77502, number of negative: 97781\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442150 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Start training from score -0.232439\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8000\n",
      "[LightGBM] [Info] Number of data points in the train set: 175283, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442148 -> initscore=-0.232450\n",
      "[LightGBM] [Info] Start training from score -0.232450\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8067\n",
      "[LightGBM] [Info] Number of data points in the train set: 175283, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442154 -> initscore=-0.232427\n",
      "[LightGBM] [Info] Start training from score -0.232427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 116252, number of negative: 146672\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8837\n",
      "[LightGBM] [Info] Number of data points in the train set: 262924, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442151 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Start training from score -0.232439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 116252, number of negative: 146672\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8837\n",
      "[LightGBM] [Info] Number of data points in the train set: 262924, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442151 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Start training from score -0.232439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 77502, number of negative: 97781\n",
      "[LightGBM] [Info] Number of positive: 77501, number of negative: 97781\n",
      "[LightGBM] [Info] Number of positive: 77501, number of negative: 97782\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8053\n",
      "[LightGBM] [Info] Number of data points in the train set: 175283, number of used features: 40\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8911\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442154 -> initscore=-0.232427\n",
      "[LightGBM] [Info] Start training from score -0.232427\n",
      "[LightGBM] [Info] Number of data points in the train set: 175282, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442150 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Start training from score -0.232439\n",
      "[LightGBM] [Info] Total Bins 7969\n",
      "[LightGBM] [Info] Number of data points in the train set: 175283, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442148 -> initscore=-0.232450\n",
      "[LightGBM] [Info] Start training from score -0.232450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- 교차 검증 평균 ROC-AUC -------------\n",
      "LightGBM: 0.8950\n",
      "XGBoost: 0.8951\n",
      "Stacking Ensemble: 0.8918\n",
      "---------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------------- 4. Stacking Ensemble 구성 --------------------------\n",
    "# StackingClassifier: base estimator로 최적의 LightGBM과 XGBoost, 메타 모델로 LogisticRegression 사용\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[('lgb', best_lgb), ('xgb', best_xgb)],\n",
    "    final_estimator=LogisticRegression(C=0.9, penalty='l2', solver='lbfgs',random_state=42),\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    passthrough=True\n",
    ")\n",
    "\n",
    "# -------------------------- 5. 교차 검증을 통한 성능 비교 --------------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores_lgb = []\n",
    "cv_scores_xgb = []\n",
    "cv_scores_stack = []\n",
    "\n",
    "# 교차 검증을 위해 numpy 배열로 변환 (SelectKBest 결과는 numpy array)\n",
    "X_fs = X_train_encoded  # 이미 numpy array\n",
    "y_array = y.values  # numpy array로 변환\n",
    "\n",
    "for train_idx, val_idx in cv.split(X_fs, y_array):\n",
    "    X_cv_train, X_cv_val = X_fs[train_idx], X_fs[val_idx]\n",
    "    y_cv_train, y_cv_val = y_array[train_idx], y_array[val_idx]\n",
    "    \n",
    "    # 개별 모델 예측 (최적 모델로 재학습)\n",
    "    best_lgb.fit(X_cv_train, y_cv_train)\n",
    "    lgb_proba = best_lgb.predict_proba(X_cv_val)[:, 1]\n",
    "    auc_lgb = roc_auc_score(y_cv_val, lgb_proba)\n",
    "    cv_scores_lgb.append(auc_lgb)\n",
    "    \n",
    "    best_xgb.fit(X_cv_train, y_cv_train)\n",
    "    xgb_proba = best_xgb.predict_proba(X_cv_val)[:, 1]\n",
    "    auc_xgb = roc_auc_score(y_cv_val, xgb_proba)\n",
    "    cv_scores_xgb.append(auc_xgb)\n",
    "    \n",
    "    # Stacking 앙상블 예측\n",
    "    stacking_clf.fit(X_cv_train, y_cv_train)\n",
    "    stack_proba = stacking_clf.predict_proba(X_cv_val)[:, 1]\n",
    "    auc_stack = roc_auc_score(y_cv_val, stack_proba)\n",
    "    cv_scores_stack.append(auc_stack)\n",
    "\n",
    "print(\"------------- 교차 검증 평균 ROC-AUC -------------\")\n",
    "print(f\"LightGBM: {np.mean(cv_scores_lgb):.4f}\")\n",
    "print(f\"XGBoost: {np.mean(cv_scores_xgb):.4f}\")\n",
    "print(f\"Stacking Ensemble: {np.mean(cv_scores_stack):.4f}\")\n",
    "print(\"---------------------------------------------------\\n\")\n",
    "\n",
    "# ------------- 교차 검증 평균 ROC-AUC -------------\n",
    "# LightGBM: 0.9141\n",
    "# XGBoost: 0.9117\n",
    "# Stacking Ensemble: 0.8943\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 145315, number of negative: 183340\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8851\n",
      "[LightGBM] [Info] Number of data points in the train set: 328655, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442151 -> initscore=-0.232439\n",
      "[LightGBM] [Info] Start training from score -0.232439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 96876, number of negative: 122227\n",
      "[LightGBM] [Info] Number of positive: 96877, number of negative: 122227\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8112\n",
      "[LightGBM] [Info] Number of data points in the train set: 219103, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442148 -> initscore=-0.232448\n",
      "[LightGBM] [Info] Start training from score -0.232448\n",
      "[LightGBM] [Info] Number of positive: 96877, number of negative: 122226\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8005\n",
      "[LightGBM] [Info] Number of data points in the train set: 219104, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442151 -> initscore=-0.232438\n",
      "[LightGBM] [Info] Start training from score -0.232438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8931\n",
      "[LightGBM] [Info] Number of data points in the train set: 219103, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.442153 -> initscore=-0.232430\n",
      "[LightGBM] [Info] Start training from score -0.232430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/najo/.conda/envs/dip/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 임계값 (ROC 기준): 0.55\n",
      "최종 제출 파일 'stacking_ensemble_submit.csv' 생성 완료!\n"
     ]
    }
   ],
   "source": [
    "# -------------------------- 6. 최종 모델 학습 및 제출 파일 생성 --------------------------\n",
    "\n",
    "# 전체 학습 데이터(Feature Selection 결과)로 Stacking 모델 학습\n",
    "stacking_clf.fit(X_train_encoded, y)\n",
    "train_pred_proba = stacking_clf.predict_proba(X_train_encoded)[:, 1]\n",
    "\n",
    "# 테스트 데이터에 대한 예측 (Stacking 앙상블)\n",
    "final_pred_proba = stacking_clf.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "# ROC Curve 계산\n",
    "fpr, tpr, thresholds = roc_curve(y, train_pred_proba)\n",
    "\n",
    "# Optimal Cut-off (Youden's Index)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"최적 임계값 (ROC 기준): {optimal_threshold:.2f}\")\n",
    "\n",
    "# 최적 임계값 적용\n",
    "final_predictions = (final_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "# 제출 파일 생성\n",
    "sample_submission = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submission['probability'] = final_predictions\n",
    "sample_submission.to_csv('./submit/stacking_ensemble_submit.csv', index=False)\n",
    "\n",
    "print(\"최종 제출 파일 'stacking_ensemble_submit.csv' 생성 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
